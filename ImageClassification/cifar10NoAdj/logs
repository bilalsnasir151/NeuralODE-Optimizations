/home/certres/bnasir/Desktop/NeuralODE-Optimizations/ImageClassification/train.py
import os
import argparse
import time
import torch
import torch.nn as nn
from model import ODEfunc, ODEBlock, get_mnist_downsampling_layers, get_fc_layers, get_cifar10_downsampling_layers
from utils import RunningAverageMeter, inf_generator, learning_rate_with_decay, accuracy, makedirs, get_logger, count_parameters
from data import get_mnist_loaders, get_cifar10_loaders
import torch.profiler

parser = argparse.ArgumentParser()
parser.add_argument('--mnist', type=eval, default=False, choices=[True, False])
parser.add_argument('--tol', type=float, default=1e-3)
parser.add_argument('--adjoint', type=eval, default=False, choices=[True, False])
parser.add_argument('--nepochs', type=int, default=160)
parser.add_argument('--lr', type=float, default=0.1)
parser.add_argument('--batch_size', type=int, default=128)
parser.add_argument('--test_batch_size', type=int, default=1000)
parser.add_argument('--save', type=str, default='./experiment1')
parser.add_argument('--debug', action='store_true')
args = parser.parse_args()

if args.adjoint:
    from torchdiffeq import odeint_adjoint as odeint
else:
    from torchdiffeq import odeint

if __name__ == '__main__':

    makedirs(args.save)
    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    
    torch.set_default_dtype(torch.float32)

    #find device
    device = torch.device("cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")
    print(device)

    #first section of network, primarily focusing on reducing spatial dimensions of input while extracting basic to complex features
    if args.mnist:
        downsampling_layers = get_mnist_downsampling_layers()
    else:
        downsampling_layers = get_cifar10_downsampling_layers()

    feature_layers = [ODEBlock(ODEfunc(64), odeint, args.tol)]
    fc_layers = get_fc_layers()

    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)

    logger.info(model)
    logger.info('Number of parameters: {}'.format(count_parameters(model)))

    criterion = nn.CrossEntropyLoss().to(device)

    if args.mnist:
        train_loader, test_loader, train_eval_loader = get_mnist_loaders(args.batch_size, args.test_batch_size)
    else:
        train_loader, test_loader, train_eval_loader = get_cifar10_loaders(args.batch_size, args.test_batch_size)

    data_gen = inf_generator(train_loader)
    batches_per_epoch = len(train_loader)

    lr_fn = learning_rate_with_decay(
        args.batch_size, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],
        decay_rates=[1, 0.1, 0.01, 0.001], lr = args.lr
    )

    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)

    best_acc = 0
    batch_time_meter = RunningAverageMeter()
    f_nfe_meter = RunningAverageMeter()
    b_nfe_meter = RunningAverageMeter()
    end = time.time()

    with torch.profiler.profile(
        activities=[
            torch.profiler.ProfilerActivity.CPU,
            torch.profiler.ProfilerActivity.CUDA
        ],
        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),
        on_trace_ready=torch.profiler.tensorboard_trace_handler(args.save),
        record_shapes=True,
        profile_memory=True,
        with_stack=True
    ) as prof:
        for itr in range(args.nepochs * batches_per_epoch):

            for param_group in optimizer.param_groups:
                param_group['lr'] = lr_fn(itr)

            optimizer.zero_grad()
            x, y = data_gen.__next__()
            x = x.to(device)
            y = y.to(device)
            logits = model(x)
            loss = criterion(logits, y)

            nfe_forward = feature_layers[0].nfe
            feature_layers[0].nfe = 0

            loss.backward()
            optimizer.step()

            nfe_backward = feature_layers[0].nfe
            feature_layers[0].nfe = 0

            batch_time_meter.update(time.time() - end)

            f_nfe_meter.update(nfe_forward)
            b_nfe_meter.update(nfe_backward)
            end = time.time()

            prof.step()  # Step the profiler

            if itr % batches_per_epoch == 0:
                with torch.no_grad():
                    train_acc = accuracy(model, train_eval_loader, device)
                    val_acc = accuracy(model, test_loader, device)
                    if val_acc > best_acc:
                        torch.save({'state_dict': model.state_dict(), 'args': args}, os.path.join(args.save, 'model.pth'))
                        best_acc = val_acc
                    logger.info(
                        "Epoch {:04d} | Time {:.3f} ({:.3f}) | NFE-F {:.1f} | NFE-B {:.1f} | "
                        "Train Acc {:.4f} | Test Acc {:.4f}".format(
                            itr // batches_per_epoch, batch_time_meter.val, batch_time_meter.avg, f_nfe_meter.avg,
                            b_nfe_meter.avg, train_acc, val_acc
                        )
                    )
    print(prof.key_averages().table(sort_by="cpu_time_total"))
    print(f"Profiling data saved to {args.save}")

Namespace(mnist=False, tol=0.001, adjoint=False, nepochs=100, lr=0.1, batch_size=128, test_batch_size=1000, save='./cifar10NoAdj', debug=False)
Sequential(
  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GroupNorm(32, 64, eps=1e-05, affine=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (4): GroupNorm(32, 64, eps=1e-05, affine=True)
  (5): ReLU(inplace=True)
  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): GroupNorm(32, 64, eps=1e-05, affine=True)
  (8): ReLU(inplace=True)
  (9): ODEBlock(
    (odefunc): ODEfunc(
      (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)
      (relu): ReLU(inplace=True)
      (conv1): ConcatConv2d(
        (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)
      (conv2): ConcatConv2d(
        (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (norm3): GroupNorm(32, 64, eps=1e-05, affine=True)
    )
  )
  (10): GroupNorm(32, 64, eps=1e-05, affine=True)
  (11): ReLU(inplace=True)
  (12): AdaptiveAvgPool2d(output_size=(1, 1))
  (13): Flatten()
  (14): Linear(in_features=64, out_features=10, bias=True)
)
Number of parameters: 209546
Epoch 0000 | Time 2.639 (2.639) | NFE-F 26.0 | NFE-B 0.0 | Train Acc 0.1000 | Test Acc 0.1000
Epoch 0001 | Time 0.316 (0.115) | NFE-F 20.4 | NFE-B 0.0 | Train Acc 0.4690 | Test Acc 0.4718
Epoch 0002 | Time 0.369 (0.063) | NFE-F 20.2 | NFE-B 0.0 | Train Acc 0.5710 | Test Acc 0.5605
Epoch 0003 | Time 0.558 (0.064) | NFE-F 20.2 | NFE-B 0.0 | Train Acc 0.6510 | Test Acc 0.6300
Epoch 0004 | Time 0.351 (0.062) | NFE-F 20.2 | NFE-B 0.0 | Train Acc 0.6880 | Test Acc 0.6573
Epoch 0005 | Time 0.323 (0.062) | NFE-F 20.2 | NFE-B 0.0 | Train Acc 0.7512 | Test Acc 0.7067
Epoch 0006 | Time 0.340 (0.076) | NFE-F 25.9 | NFE-B 0.0 | Train Acc 0.7806 | Test Acc 0.7272
Epoch 0007 | Time 0.329 (0.076) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.8098 | Test Acc 0.7480
Epoch 0008 | Time 0.334 (0.076) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.8171 | Test Acc 0.7461
Epoch 0009 | Time 0.375 (0.076) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.8475 | Test Acc 0.7653
Epoch 0010 | Time 0.386 (0.076) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.8560 | Test Acc 0.7584
Epoch 0011 | Time 0.364 (0.076) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.8787 | Test Acc 0.7688
Epoch 0012 | Time 0.329 (0.075) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.8858 | Test Acc 0.7673
Epoch 0013 | Time 4.438 (0.116) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9082 | Test Acc 0.7756
Epoch 0014 | Time 0.415 (0.079) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9109 | Test Acc 0.7741
Epoch 0015 | Time 0.393 (0.078) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9141 | Test Acc 0.7649
Epoch 0016 | Time 0.371 (0.079) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.8867 | Test Acc 0.7458
Epoch 0017 | Time 0.355 (0.076) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9185 | Test Acc 0.7661
Epoch 0018 | Time 0.353 (0.077) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9406 | Test Acc 0.7704
Epoch 0019 | Time 0.365 (0.077) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9491 | Test Acc 0.7756
Epoch 0020 | Time 0.335 (0.076) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9524 | Test Acc 0.7659
Epoch 0021 | Time 0.394 (0.079) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9568 | Test Acc 0.7679
Epoch 0022 | Time 0.355 (0.076) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9387 | Test Acc 0.7622
Epoch 0023 | Time 0.424 (0.076) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9441 | Test Acc 0.7595
Epoch 0024 | Time 0.332 (0.078) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9662 | Test Acc 0.7688
Epoch 0025 | Time 0.394 (0.079) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9810 | Test Acc 0.7708
Epoch 0026 | Time 0.485 (0.079) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9693 | Test Acc 0.7671
Epoch 0027 | Time 0.388 (0.079) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9754 | Test Acc 0.7674
Epoch 0028 | Time 0.375 (0.078) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9698 | Test Acc 0.7739
Epoch 0029 | Time 0.365 (0.075) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9867 | Test Acc 0.7835
Epoch 0030 | Time 0.337 (0.078) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9937 | Test Acc 0.7821
Epoch 0031 | Time 0.369 (0.079) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9900 | Test Acc 0.7781
Epoch 0032 | Time 0.388 (0.078) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9905 | Test Acc 0.7728
Epoch 0033 | Time 0.428 (0.088) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9929 | Test Acc 0.7755
Epoch 0034 | Time 0.370 (0.085) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 0.9998 | Test Acc 0.7838
Epoch 0035 | Time 1.326 (0.097) | NFE-F 26.3 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7859
Epoch 0036 | Time 1.380 (0.098) | NFE-F 26.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7883
Epoch 0037 | Time 0.370 (0.092) | NFE-F 27.6 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7880
Epoch 0038 | Time 0.405 (0.098) | NFE-F 30.7 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7886
Epoch 0039 | Time 0.383 (0.102) | NFE-F 31.9 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7895
Epoch 0040 | Time 0.369 (0.098) | NFE-F 32.2 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7882
Epoch 0041 | Time 0.389 (0.101) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7896
Epoch 0042 | Time 0.455 (0.101) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7886
Epoch 0043 | Time 0.420 (0.101) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7893
Epoch 0044 | Time 1.805 (0.112) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7898
Epoch 0045 | Time 0.422 (0.100) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7885
Epoch 0046 | Time 0.383 (0.101) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7884
Epoch 0047 | Time 0.404 (0.100) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7888
Epoch 0048 | Time 0.363 (0.101) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7893
Epoch 0049 | Time 0.398 (0.104) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7892
Epoch 0050 | Time 0.428 (0.104) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7883
Epoch 0051 | Time 0.384 (0.105) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7898
Epoch 0052 | Time 0.379 (0.105) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7884
Epoch 0053 | Time 2.577 (0.123) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7887
Epoch 0054 | Time 0.354 (0.104) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7897
Epoch 0055 | Time 0.355 (0.103) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7887
Epoch 0056 | Time 0.371 (0.103) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7886
Epoch 0057 | Time 0.357 (0.103) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7887
Epoch 0058 | Time 0.361 (0.102) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7893
Epoch 0059 | Time 4.704 (0.145) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7891
Epoch 0060 | Time 0.434 (0.101) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7888
Epoch 0061 | Time 0.413 (0.097) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7888
Epoch 0062 | Time 0.362 (0.096) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7888
Epoch 0063 | Time 0.381 (0.098) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7887
Epoch 0064 | Time 0.434 (0.100) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7891
Epoch 0065 | Time 0.371 (0.099) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7888
Epoch 0066 | Time 0.355 (0.098) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7891
Epoch 0067 | Time 0.409 (0.098) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7889
Epoch 0068 | Time 0.372 (0.102) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7890
Epoch 0069 | Time 0.356 (0.099) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7890
Epoch 0070 | Time 0.350 (0.103) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7890
Epoch 0071 | Time 0.388 (0.101) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7891
Epoch 0072 | Time 0.387 (0.102) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7891
Epoch 0073 | Time 0.357 (0.103) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7888
Epoch 0074 | Time 0.387 (0.101) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7890
Epoch 0075 | Time 0.389 (0.100) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7891
Epoch 0076 | Time 0.373 (0.096) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7891
Epoch 0077 | Time 0.370 (0.096) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7889
Epoch 0078 | Time 1.680 (0.114) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7890
Epoch 0079 | Time 0.360 (0.099) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7890
Epoch 0080 | Time 0.413 (0.100) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7889
Epoch 0081 | Time 0.378 (0.103) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7891
Epoch 0082 | Time 0.381 (0.105) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7889
Epoch 0083 | Time 0.397 (0.103) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7892
Epoch 0084 | Time 0.384 (0.099) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7890
Epoch 0085 | Time 0.377 (0.104) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7892
Epoch 0086 | Time 0.360 (0.101) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7892
Epoch 0087 | Time 0.415 (0.101) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7890
Epoch 0088 | Time 0.371 (0.102) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7891
Epoch 0089 | Time 0.381 (0.097) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7889
Epoch 0090 | Time 0.362 (0.099) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7890
Epoch 0091 | Time 0.360 (0.097) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7890
Epoch 0092 | Time 0.355 (0.100) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7890
Epoch 0093 | Time 0.364 (0.096) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7889
Epoch 0094 | Time 0.358 (0.097) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7889
Epoch 0095 | Time 0.712 (0.105) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7890
Epoch 0096 | Time 0.389 (0.102) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7888
Epoch 0097 | Time 0.385 (0.101) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7889
Epoch 0098 | Time 0.374 (0.102) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7888
Epoch 0099 | Time 0.382 (0.104) | NFE-F 32.4 | NFE-B 0.0 | Train Acc 1.0000 | Test Acc 0.7889
