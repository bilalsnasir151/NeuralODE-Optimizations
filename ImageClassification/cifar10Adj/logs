/home/certres/bnasir/Desktop/NeuralODE-Optimizations/ImageClassification/train.py
import os
import argparse
import time
import torch
import torch.nn as nn
from model import ODEfunc, ODEBlock, get_mnist_downsampling_layers, get_fc_layers, get_cifar10_downsampling_layers
from utils import RunningAverageMeter, inf_generator, learning_rate_with_decay, accuracy, makedirs, get_logger, count_parameters
from data import get_mnist_loaders, get_cifar10_loaders
import torch.profiler

parser = argparse.ArgumentParser()
parser.add_argument('--mnist', type=eval, default=False, choices=[True, False])
parser.add_argument('--tol', type=float, default=1e-3)
parser.add_argument('--adjoint', type=eval, default=False, choices=[True, False])
parser.add_argument('--nepochs', type=int, default=160)
parser.add_argument('--lr', type=float, default=0.1)
parser.add_argument('--batch_size', type=int, default=128)
parser.add_argument('--test_batch_size', type=int, default=1000)
parser.add_argument('--save', type=str, default='./experiment1')
parser.add_argument('--debug', action='store_true')
args = parser.parse_args()

if args.adjoint:
    from torchdiffeq import odeint_adjoint as odeint
else:
    from torchdiffeq import odeint

if __name__ == '__main__':

    makedirs(args.save)
    logger = get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))
    logger.info(args)
    
    torch.set_default_dtype(torch.float32)

    #find device
    device = torch.device("cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")
    print(device)

    #first section of network, primarily focusing on reducing spatial dimensions of input while extracting basic to complex features
    if args.mnist:
        downsampling_layers = get_mnist_downsampling_layers()
    else:
        downsampling_layers = get_cifar10_downsampling_layers()

    feature_layers = [ODEBlock(ODEfunc(64), odeint, args.tol)]
    fc_layers = get_fc_layers()

    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers).to(device)

    logger.info(model)
    logger.info('Number of parameters: {}'.format(count_parameters(model)))

    criterion = nn.CrossEntropyLoss().to(device)

    if args.mnist:
        train_loader, test_loader, train_eval_loader = get_mnist_loaders(args.batch_size, args.test_batch_size)
    else:
        train_loader, test_loader, train_eval_loader = get_cifar10_loaders(args.batch_size, args.test_batch_size)

    data_gen = inf_generator(train_loader)
    batches_per_epoch = len(train_loader)

    lr_fn = learning_rate_with_decay(
        args.batch_size, batch_denom=128, batches_per_epoch=batches_per_epoch, boundary_epochs=[60, 100, 140],
        decay_rates=[1, 0.1, 0.01, 0.001], lr = args.lr
    )

    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)

    best_acc = 0
    batch_time_meter = RunningAverageMeter()
    f_nfe_meter = RunningAverageMeter()
    b_nfe_meter = RunningAverageMeter()
    end = time.time()

    with torch.profiler.profile(
        activities=[
            torch.profiler.ProfilerActivity.CPU,
            torch.profiler.ProfilerActivity.CUDA
        ],
        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),
        on_trace_ready=torch.profiler.tensorboard_trace_handler(args.save),
        record_shapes=True,
        profile_memory=True,
        with_stack=True
    ) as prof:
        for itr in range(args.nepochs * batches_per_epoch):

            for param_group in optimizer.param_groups:
                param_group['lr'] = lr_fn(itr)

            optimizer.zero_grad()
            x, y = data_gen.__next__()
            x = x.to(device)
            y = y.to(device)
            logits = model(x)
            loss = criterion(logits, y)

            nfe_forward = feature_layers[0].nfe
            feature_layers[0].nfe = 0

            loss.backward()
            optimizer.step()

            nfe_backward = feature_layers[0].nfe
            feature_layers[0].nfe = 0

            batch_time_meter.update(time.time() - end)

            f_nfe_meter.update(nfe_forward)
            b_nfe_meter.update(nfe_backward)
            end = time.time()

            prof.step()  # Step the profiler

            if itr % batches_per_epoch == 0:
                with torch.no_grad():
                    train_acc = accuracy(model, train_eval_loader, device)
                    val_acc = accuracy(model, test_loader, device)
                    if val_acc > best_acc:
                        torch.save({'state_dict': model.state_dict(), 'args': args}, os.path.join(args.save, 'model.pth'))
                        best_acc = val_acc
                    logger.info(
                        "Epoch {:04d} | Time {:.3f} ({:.3f}) | NFE-F {:.1f} | NFE-B {:.1f} | "
                        "Train Acc {:.4f} | Test Acc {:.4f}".format(
                            itr // batches_per_epoch, batch_time_meter.val, batch_time_meter.avg, f_nfe_meter.avg,
                            b_nfe_meter.avg, train_acc, val_acc
                        )
                    )
    print(prof.key_averages().table(sort_by="cpu_time_total"))
    print(f"Profiling data saved to {args.save}")

Namespace(mnist=False, tol=0.001, adjoint=True, nepochs=100, lr=0.1, batch_size=128, test_batch_size=1000, save='./cifar10Adj', debug=False)
Sequential(
  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GroupNorm(32, 64, eps=1e-05, affine=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (4): GroupNorm(32, 64, eps=1e-05, affine=True)
  (5): ReLU(inplace=True)
  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): GroupNorm(32, 64, eps=1e-05, affine=True)
  (8): ReLU(inplace=True)
  (9): ODEBlock(
    (odefunc): ODEfunc(
      (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)
      (relu): ReLU(inplace=True)
      (conv1): ConcatConv2d(
        (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)
      (conv2): ConcatConv2d(
        (_layer): Conv2d(65, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (norm3): GroupNorm(32, 64, eps=1e-05, affine=True)
    )
  )
  (10): GroupNorm(32, 64, eps=1e-05, affine=True)
  (11): ReLU(inplace=True)
  (12): AdaptiveAvgPool2d(output_size=(1, 1))
  (13): Flatten()
  (14): Linear(in_features=64, out_features=10, bias=True)
)
Number of parameters: 209546
Epoch 0000 | Time 2.591 (2.591) | NFE-F 26.0 | NFE-B 20.0 | Train Acc 0.1362 | Test Acc 0.1377
Epoch 0001 | Time 0.402 (0.150) | NFE-F 20.4 | NFE-B 20.0 | Train Acc 0.4397 | Test Acc 0.4392
Epoch 0002 | Time 0.977 (0.104) | NFE-F 20.2 | NFE-B 20.0 | Train Acc 0.5657 | Test Acc 0.5538
Epoch 0003 | Time 0.438 (0.098) | NFE-F 20.2 | NFE-B 20.0 | Train Acc 0.6067 | Test Acc 0.5818
Epoch 0004 | Time 0.496 (0.097) | NFE-F 20.4 | NFE-B 20.0 | Train Acc 0.6947 | Test Acc 0.6588
Epoch 0005 | Time 0.510 (0.106) | NFE-F 26.0 | NFE-B 20.0 | Train Acc 0.7208 | Test Acc 0.6805
Epoch 0006 | Time 0.407 (0.105) | NFE-F 26.3 | NFE-B 20.0 | Train Acc 0.7582 | Test Acc 0.7084
Epoch 0007 | Time 0.407 (0.106) | NFE-F 26.3 | NFE-B 20.1 | Train Acc 0.7920 | Test Acc 0.7277
Epoch 0008 | Time 0.594 (0.108) | NFE-F 26.3 | NFE-B 20.3 | Train Acc 0.8110 | Test Acc 0.7429
Epoch 0009 | Time 0.408 (0.107) | NFE-F 26.3 | NFE-B 20.8 | Train Acc 0.8362 | Test Acc 0.7509
Epoch 0010 | Time 0.458 (0.109) | NFE-F 26.3 | NFE-B 21.5 | Train Acc 0.8327 | Test Acc 0.7455
Epoch 0011 | Time 0.468 (0.116) | NFE-F 26.3 | NFE-B 23.6 | Train Acc 0.8708 | Test Acc 0.7645
Epoch 0012 | Time 0.489 (0.122) | NFE-F 26.3 | NFE-B 25.5 | Train Acc 0.8233 | Test Acc 0.7290
Epoch 0013 | Time 0.432 (0.123) | NFE-F 26.3 | NFE-B 25.9 | Train Acc 0.8874 | Test Acc 0.7620
Epoch 0014 | Time 0.505 (0.125) | NFE-F 26.3 | NFE-B 26.0 | Train Acc 0.8938 | Test Acc 0.7659
Epoch 0015 | Time 0.436 (0.123) | NFE-F 26.3 | NFE-B 26.0 | Train Acc 0.9088 | Test Acc 0.7639
Epoch 0016 | Time 0.475 (0.123) | NFE-F 26.3 | NFE-B 26.0 | Train Acc 0.8985 | Test Acc 0.7603
Epoch 0017 | Time 0.435 (0.122) | NFE-F 26.3 | NFE-B 26.0 | Train Acc 0.9272 | Test Acc 0.7646
Epoch 0018 | Time 0.426 (0.120) | NFE-F 26.3 | NFE-B 26.0 | Train Acc 0.9358 | Test Acc 0.7685
Epoch 0019 | Time 0.535 (0.122) | NFE-F 26.3 | NFE-B 26.1 | Train Acc 0.9368 | Test Acc 0.7642
Epoch 0020 | Time 0.482 (0.120) | NFE-F 26.3 | NFE-B 26.0 | Train Acc 0.9330 | Test Acc 0.7588
Epoch 0021 | Time 0.475 (0.122) | NFE-F 26.3 | NFE-B 26.0 | Train Acc 0.9340 | Test Acc 0.7575
Epoch 0022 | Time 0.436 (0.121) | NFE-F 26.3 | NFE-B 26.1 | Train Acc 0.9426 | Test Acc 0.7605
Epoch 0023 | Time 0.441 (0.121) | NFE-F 26.4 | NFE-B 26.1 | Train Acc 0.9551 | Test Acc 0.7592
Epoch 0024 | Time 0.424 (0.121) | NFE-F 26.5 | NFE-B 26.4 | Train Acc 0.9438 | Test Acc 0.7538
Epoch 0025 | Time 0.493 (0.123) | NFE-F 27.6 | NFE-B 26.3 | Train Acc 0.9587 | Test Acc 0.7601
Epoch 0026 | Time 0.437 (0.123) | NFE-F 27.5 | NFE-B 26.2 | Train Acc 0.9765 | Test Acc 0.7616
Epoch 0027 | Time 0.477 (0.126) | NFE-F 29.5 | NFE-B 26.7 | Train Acc 0.9666 | Test Acc 0.7590
Epoch 0028 | Time 0.416 (0.127) | NFE-F 31.3 | NFE-B 26.3 | Train Acc 0.9678 | Test Acc 0.7547
Epoch 0029 | Time 0.551 (0.138) | NFE-F 32.3 | NFE-B 30.0 | Train Acc 0.9889 | Test Acc 0.7645
Epoch 0030 | Time 0.447 (0.133) | NFE-F 32.4 | NFE-B 28.0 | Train Acc 0.9719 | Test Acc 0.7619
Epoch 0031 | Time 0.448 (0.127) | NFE-F 31.7 | NFE-B 26.4 | Train Acc 0.9775 | Test Acc 0.7605
Epoch 0032 | Time 0.424 (0.129) | NFE-F 32.3 | NFE-B 26.6 | Train Acc 0.9802 | Test Acc 0.7662
Epoch 0033 | Time 0.498 (0.137) | NFE-F 32.4 | NFE-B 29.5 | Train Acc 0.9841 | Test Acc 0.7596
Epoch 0034 | Time 0.489 (0.134) | NFE-F 32.4 | NFE-B 28.0 | Train Acc 0.9871 | Test Acc 0.7657
Epoch 0035 | Time 0.470 (0.140) | NFE-F 32.4 | NFE-B 30.4 | Train Acc 0.9975 | Test Acc 0.7691
Epoch 0036 | Time 0.521 (0.144) | NFE-F 32.4 | NFE-B 31.9 | Train Acc 0.9996 | Test Acc 0.7735
Epoch 0037 | Time 0.503 (0.144) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7799
Epoch 0038 | Time 0.507 (0.145) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7797
Epoch 0039 | Time 0.510 (0.145) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7787
Epoch 0040 | Time 5.421 (0.193) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7798
Epoch 0041 | Time 0.506 (0.145) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7793
Epoch 0042 | Time 0.519 (0.145) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7793
Epoch 0043 | Time 0.596 (0.145) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7796
Epoch 0044 | Time 0.449 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7798
Epoch 0045 | Time 0.511 (0.145) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7793
Epoch 0046 | Time 0.452 (0.144) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7793
Epoch 0047 | Time 0.535 (0.145) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0048 | Time 0.529 (0.147) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7797
Epoch 0049 | Time 0.495 (0.144) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7791
Epoch 0050 | Time 0.464 (0.145) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7791
Epoch 0051 | Time 2.017 (0.157) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7796
Epoch 0052 | Time 0.498 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7793
Epoch 0053 | Time 0.444 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7790
Epoch 0054 | Time 0.519 (0.144) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7793
Epoch 0055 | Time 2.543 (0.164) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7790
Epoch 0056 | Time 0.457 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7794
Epoch 0057 | Time 0.787 (0.147) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7793
Epoch 0058 | Time 0.447 (0.144) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7784
Epoch 0059 | Time 0.500 (0.144) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7786
Epoch 0060 | Time 0.447 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7785
Epoch 0061 | Time 0.440 (0.144) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0062 | Time 3.313 (0.172) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0063 | Time 0.470 (0.145) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0064 | Time 2.080 (0.161) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7790
Epoch 0065 | Time 0.530 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7790
Epoch 0066 | Time 0.509 (0.142) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7788
Epoch 0067 | Time 0.493 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7788
Epoch 0068 | Time 0.501 (0.144) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0069 | Time 0.446 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0070 | Time 0.525 (0.144) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7790
Epoch 0071 | Time 0.454 (0.142) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0072 | Time 0.499 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7788
Epoch 0073 | Time 0.508 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7790
Epoch 0074 | Time 0.507 (0.142) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0075 | Time 0.508 (0.142) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0076 | Time 0.506 (0.142) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7790
Epoch 0077 | Time 0.494 (0.142) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0078 | Time 0.495 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0079 | Time 0.463 (0.142) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7788
Epoch 0080 | Time 0.447 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7790
Epoch 0081 | Time 0.521 (0.144) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0082 | Time 0.444 (0.142) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7791
Epoch 0083 | Time 0.537 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7793
Epoch 0084 | Time 0.488 (0.142) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7791
Epoch 0085 | Time 0.489 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0086 | Time 0.457 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0087 | Time 0.509 (0.142) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7790
Epoch 0088 | Time 4.338 (0.180) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7791
Epoch 0089 | Time 0.459 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7791
Epoch 0090 | Time 0.491 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7792
Epoch 0091 | Time 0.503 (0.145) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0092 | Time 0.970 (0.150) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7790
Epoch 0093 | Time 0.508 (0.144) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
Epoch 0094 | Time 0.456 (0.142) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7788
Epoch 0095 | Time 0.518 (0.142) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7790
Epoch 0096 | Time 1.050 (0.147) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7791
Epoch 0097 | Time 0.488 (0.142) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7788
Epoch 0098 | Time 0.516 (0.143) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7790
Epoch 0099 | Time 0.498 (0.142) | NFE-F 32.4 | NFE-B 32.0 | Train Acc 1.0000 | Test Acc 0.7789
